{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64230006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (8217, 2000) (2055, 2000)\n",
      "a=4.3288 | w*=0.0000 | best_w=0.0000 | mse=29.166091\n",
      "a=5.4496 | w*=0.0000 | best_w=0.0000 | mse=28.959012\n",
      "a=6.8606 | w*=0.0000 | best_w=0.0000 | mse=28.769466\n",
      "a=8.637 | w*=0.0000 | best_w=0.0000 | mse=28.596657\n",
      "a=10.873 | w*=0.0000 | best_w=0.0000 | mse=28.439481\n",
      "a=13.689 | w*=0.0000 | best_w=0.0000 | mse=28.296798\n",
      "a=17.233 | w*=0.0000 | best_w=0.0000 | mse=28.167643\n",
      "a=21.695 | w*=0.0000 | best_w=0.0000 | mse=28.051372\n",
      "a=27.313 | w*=0.0000 | best_w=0.0000 | mse=27.947750\n",
      "a=34.385 | w*=0.0000 | best_w=0.0000 | mse=27.857071\n",
      "a=43.288 | w*=0.0016 | best_w=0.0020 | mse=27.780251\n",
      "a=54.496 | w*=0.0067 | best_w=0.0070 | mse=27.718386\n",
      "a=68.606 | w*=0.0123 | best_w=0.0120 | mse=27.673817\n",
      "a=86.37 | w*=0.0188 | best_w=0.0190 | mse=27.650065\n",
      "a=108.73 | w*=0.0263 | best_w=0.0260 | mse=27.651689\n",
      "a=136.89 | w*=0.0350 | best_w=0.0350 | mse=27.684156\n",
      "a=172.33 | w*=0.0452 | best_w=0.0450 | mse=27.753584\n",
      "a=216.95 | w*=0.0573 | best_w=0.0573 | mse=27.866292\n",
      "a=273.13 | w*=0.0713 | best_w=0.0713 | mse=28.028188\n",
      "a=343.85 | w*=0.0875 | best_w=0.0875 | mse=28.243996\n",
      "a=432.88 | w*=0.1059 | best_w=0.1059 | mse=28.516452\n",
      "\n",
      "BEST: {'mse': 27.650064909412155, 'alpha': 86.37014254641434, 'w': 0.019, 'mse_lr': 47.424912698970466, 'mse_ridge': 27.657311754180974}\n",
      "Saved: submission_refactored.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, KBinsDiscretizer, PowerTransformer,\n",
    "    PolynomialFeatures, FunctionTransformer\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "OUT_FILE = \"submission_refactored.csv\"\n",
    "\n",
    "if not os.path.isfile(TRAIN_FILE):\n",
    "    raise FileNotFoundError(TRAIN_FILE)\n",
    "\n",
    "\n",
    "def safe_log_plus_one(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Numerically stable log1p transformer.\"\"\"\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    if s.isnull().all():\n",
    "        return s\n",
    "    mn = s.min(skipna=True)\n",
    "    if pd.notna(mn) and mn < 0:\n",
    "        s = s + abs(mn) + 1\n",
    "    return np.log1p(s.fillna(0))\n",
    "\n",
    "\n",
    "def blended_weight(y, a, b):\n",
    "    d = a - b\n",
    "    denom = np.dot(d, d)\n",
    "    if denom == 0:\n",
    "        return 0.5\n",
    "    w = np.dot(d, (y - b)) / denom\n",
    "    return float(np.clip(w, 0, 1))\n",
    "\n",
    "\n",
    "train_raw = pd.read_csv(TRAIN_FILE)\n",
    "test_raw = pd.read_csv(TEST_FILE) if os.path.exists(TEST_FILE) else None\n",
    "\n",
    "\n",
    "def initial_cleanup(df: pd.DataFrame, train_mode=True) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    if train_mode and \"RiskScore\" in df:\n",
    "        df = df[df[\"RiskScore\"].between(0, 100)].copy()\n",
    "\n",
    "    df.replace(-9999999.0, np.nan, inplace=True)\n",
    "\n",
    "    if \"ApplicationDate\" in df:\n",
    "        dt = pd.to_datetime(df[\"ApplicationDate\"], errors=\"coerce\")\n",
    "        df[\"App_Year\"] = dt.dt.year.fillna(0).astype(int)\n",
    "        df[\"App_Month\"] = dt.dt.month.fillna(0).astype(int)\n",
    "        df[\"App_DayOfWeek\"] = dt.dt.dayofweek.fillna(0).astype(int)\n",
    "\n",
    "    eps = 1e-6\n",
    "\n",
    "    if {\"MonthlyLoanPayment\", \"MonthlyIncome\"} <= set(df.columns):\n",
    "        df[\"PaymentToIncomeRatio\"] = df[\"MonthlyLoanPayment\"] / (df[\"MonthlyIncome\"] + eps)\n",
    "\n",
    "    if {\"LoanAmount\", \"AnnualIncome\"} <= set(df.columns):\n",
    "        df[\"LoanToIncomeRatio\"] = df[\"LoanAmount\"] / (df[\"AnnualIncome\"] + eps)\n",
    "\n",
    "    if {\"TotalLiabilities\", \"TotalAssets\"} <= set(df.columns):\n",
    "        df[\"DebtToAssetsRatio\"] = df[\"TotalLiabilities\"] / (df[\"TotalAssets\"] + eps)\n",
    "\n",
    "    if {\"SavingsAccountBalance\", \"LoanAmount\"} <= set(df.columns):\n",
    "        df[\"SavingsToLoanRatio\"] = df[\"SavingsAccountBalance\"] / (df[\"LoanAmount\"] + eps)\n",
    "\n",
    "    if {\"LengthOfCreditHistory\", \"PaymentHistory\"} <= set(df.columns):\n",
    "        df[\"CreditHistoryInteraction\"] = df[\"LengthOfCreditHistory\"] * df[\"PaymentHistory\"]\n",
    "\n",
    "    if {\"MonthlyIncome\", \"CreditScore\"} <= set(df.columns):\n",
    "        df[\"Income_x_CreditScore\"] = df[\"MonthlyIncome\"].fillna(0) * df[\"CreditScore\"].fillna(0)\n",
    "\n",
    "    clip_targets = [\n",
    "        \"MonthlyIncome\",\"LoanAmount\",\"AnnualIncome\",\"SavingsAccountBalance\",\n",
    "        \"TotalAssets\",\"TotalLiabilities\",\"MonthlyDebtPayments\"\n",
    "    ]\n",
    "    for c in clip_targets:\n",
    "        if c in df:\n",
    "            lo, hi = df[c].quantile([0.01, 0.99])\n",
    "            df[c] = df[c].clip(lo, hi)\n",
    "\n",
    "    log_cols = [\n",
    "        \"MonthlyIncome\",\"LoanAmount\",\"SavingsAccountBalance\",\"CheckingAccountBalance\",\n",
    "        \"TotalAssets\",\"TotalLiabilities\",\"NetWorth\",\"MonthlyDebtPayments\"\n",
    "    ]\n",
    "    for c in log_cols:\n",
    "        if c in df:\n",
    "            df[c] = safe_log_plus_one(df[c])\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "train = initial_cleanup(train_raw, True)\n",
    "test = initial_cleanup(test_raw, False) if test_raw is not None else None\n",
    "\n",
    "\n",
    "TARGET = \"RiskScore\"\n",
    "\n",
    "num_raw = [\n",
    "    'CreditScore','MonthlyIncome','BaseInterestRate','LoanAmount','LoanDuration',\n",
    "    'DebtToIncomeRatio','NumberOfDependents','NumberOfOpenCreditLines','NumberOfCreditInquiries',\n",
    "    'PaymentHistory','LengthOfCreditHistory','UtilityBillsPaymentHistory','MonthlyDebtPayments',\n",
    "    'CreditCardUtilizationRate','InterestRate','TotalDebtToIncomeRatio','SavingsAccountBalance',\n",
    "    'CheckingAccountBalance','TotalAssets','TotalLiabilities','NetWorth','JobTenure','Experience','Age',\n",
    "    'BankruptcyHistory','PreviousLoanDefaults','PaymentToIncomeRatio','LoanToIncomeRatio','DebtToAssetsRatio',\n",
    "    'SavingsToLoanRatio','CreditHistoryInteraction','Income_x_CreditScore',\n",
    "    'App_Year','App_Month','App_DayOfWeek'\n",
    "]\n",
    "\n",
    "cat_raw = [\"MaritalStatus\",\"HomeOwnershipStatus\",\"EmploymentStatus\",\"EducationLevel\",\"LoanPurpose\"]\n",
    "binned_candidates = [\"Age\", \"CreditScore\"]\n",
    "\n",
    "nums = [c for c in num_raw if c in train]\n",
    "cats = [c for c in cat_raw if c in train]\n",
    "bnd = [c for c in binned_candidates if c in train]\n",
    "nums_final = [c for c in nums if c not in bnd]\n",
    "all_cols = nums_final + cats + bnd\n",
    "\n",
    "\n",
    "def high_corr_drop(df, cols, threshold=0.95):\n",
    "    tmp = df[cols].select_dtypes(include=[np.number]).copy()\n",
    "    cmat = tmp.corr().abs()\n",
    "    upper = cmat.where(np.triu(np.ones(cmat.shape), 1).astype(bool))\n",
    "    dropped = [c for c in upper.columns if any(upper[c] > threshold)]\n",
    "    return dropped\n",
    "\n",
    "drop_cols = high_corr_drop(train, nums_final)\n",
    "if drop_cols:\n",
    "    nums_final = [x for x in nums_final if x not in drop_cols]\n",
    "    all_cols = nums_final + cats + bnd\n",
    "\n",
    "\n",
    "train = train.dropna(subset=[TARGET])\n",
    "X = train[all_cols]\n",
    "y = train[TARGET]\n",
    "\n",
    "try:\n",
    "    y_bins = pd.cut(y, bins=6, labels=False)\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2,\n",
    "                                              random_state=SEED, stratify=y_bins)\n",
    "except:\n",
    "    X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"pt\", PowerTransformer(method=\"yeo-johnson\"))\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(fill_value=\"Missing\", strategy=\"constant\")),\n",
    "    (\"oh\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "bin_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"kb\", KBinsDiscretizer(n_bins=40, encode=\"onehot-dense\", strategy=\"quantile\"))\n",
    "])\n",
    "\n",
    "col_tf = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, nums_final),\n",
    "    (\"cat\", cat_pipe, cats),\n",
    "    (\"bin\", bin_pipe, bnd)\n",
    "])\n",
    "\n",
    "feature_pipe = Pipeline([\n",
    "    (\"prep\", col_tf),\n",
    "    (\"vt\", VarianceThreshold(1e-5)),\n",
    "    (\"k1\", SelectKBest(f_regression, k=min(1000, X_tr.shape[1]))),\n",
    "    (\"poly\", PolynomialFeatures(degree=3, interaction_only=False, include_bias=False)),\n",
    "    (\"k2\", SelectKBest(f_regression, k=min(2000, 5000)))\n",
    "])\n",
    "\n",
    "Xt_tr = feature_pipe.fit_transform(X_tr, y_tr)\n",
    "Xt_va = feature_pipe.transform(X_va)\n",
    "\n",
    "print(\"Shapes:\", Xt_tr.shape, Xt_va.shape)\n",
    "\n",
    "\n",
    "prev_alpha = 43.28761281083057\n",
    "grid = np.logspace(np.log10(prev_alpha/10), np.log10(prev_alpha*10), 21)\n",
    "\n",
    "best = {\"mse\": 1e9}\n",
    "\n",
    "for alpha in grid:\n",
    "    try:\n",
    "        model_r = Ridge(alpha=float(alpha)).fit(Xt_tr, y_tr)\n",
    "        model_l = LinearRegression().fit(Xt_tr, y_tr)\n",
    "\n",
    "        p_l = np.clip(model_l.predict(Xt_va), 0, 100)\n",
    "        p_r = np.clip(model_r.predict(Xt_va), 0, 100)\n",
    "\n",
    "        w_opt = blended_weight(y_va.values, p_l, p_r)\n",
    "        w_min, w_max = max(0, w_opt - 0.05), min(1, w_opt + 0.05)\n",
    "\n",
    "        if w_max <= w_min:\n",
    "            weights = [w_opt]\n",
    "        else:\n",
    "            weights = np.arange(w_min, w_max + 1e-12, 0.001)\n",
    "\n",
    "        best_local = (None, 1e9)\n",
    "        for w in weights:\n",
    "            mix = np.clip(w * p_l + (1 - w) * p_r, 0, 100)\n",
    "            mse = mean_squared_error(y_va, mix)\n",
    "            if mse < best_local[1]:\n",
    "                best_local = (w, mse)\n",
    "\n",
    "        if best_local[1] < best[\"mse\"]:\n",
    "            best.update({\n",
    "                \"alpha\": float(alpha),\n",
    "                \"w\": float(best_local[0]),\n",
    "                \"mse\": float(best_local[1]),\n",
    "                \"mse_lr\": float(mean_squared_error(y_va, p_l)),\n",
    "                \"mse_ridge\": float(mean_squared_error(y_va, p_r))\n",
    "            })\n",
    "\n",
    "        print(f\"a={alpha:.5g} | w*={w_opt:.4f} | best_w={best_local[0]:.4f} | mse={best_local[1]:.6f}\")\n",
    "\n",
    "    except Exception as err:\n",
    "        print(\"Failed:\", alpha, \"|\", err)\n",
    "\n",
    "\n",
    "print(\"\\nBEST:\", best)\n",
    "\n",
    "\n",
    "if best[\"mse\"] < 1e8:\n",
    "    a = best[\"alpha\"]\n",
    "    w = best[\"w\"]\n",
    "\n",
    "    X_full = pd.concat([X_tr, X_va])\n",
    "    y_full = pd.concat([y_tr, y_va])\n",
    "\n",
    "    Xt_full = feature_pipe.fit_transform(X_full, y_full)\n",
    "    Xt_test = feature_pipe.transform(test[all_cols]) if test is not None else None\n",
    "\n",
    "    modelL = LinearRegression().fit(Xt_full, y_full)\n",
    "    modelR = Ridge(alpha=a).fit(Xt_full, y_full)\n",
    "\n",
    "    if Xt_test is not None:\n",
    "        pL = np.clip(modelL.predict(Xt_test), 0, 100)\n",
    "        pR = np.clip(modelR.predict(Xt_test), 0, 100)\n",
    "        final = np.clip(w * pL + (1 - w) * pR, 0, 100)\n",
    "\n",
    "        out = pd.DataFrame({\n",
    "            \"ID\": test[\"ID\"] if \"ID\" in test else np.arange(len(final)),\n",
    "            \"RiskScore\": final\n",
    "        })\n",
    "        out.to_csv(OUT_FILE, index=False)\n",
    "        print(\"Saved:\", OUT_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
